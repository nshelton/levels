<html><head>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.8.2/underscore-min.js"></script>
	<script src="/js/three.min.js"></script>
	<script src="/js/three.util.js"></script>
	<script src="/three-audio-experiments/vendor/microevent.js"></script>
	<script src="/three-audio-experiments/vendor/dsp.js"></script>
	<script src="/js/TrackballControls.js"></script>
	<script src="/js/jquery.min.js"></script>
	<script src="/js/stats.min.js"></script>
	<script src="/three-audio-experiments/build/ThreeAudio.js"></script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-26353276-1', 'auto');
  ga('send', 'pageview');
</script>

</head>
<body style="margin:0">

<!-- audio material shader -->
<script type="application/x-glsl" id="vertex">
	// Audio data textures
	uniform sampler2D freqData;
	uniform sampler2D timeData;

	// Offset and sample size for sampling data textures
	uniform float audioOffset;
	uniform vec2 audioStep;

	// Beat detection. Is = 0 or 1, Was = smoothed value.
	uniform float audioIsBeat;
	uniform float audioWasBeat;

	// Precalculated audio levels, the components being (all, bass, mid, treble).
	// Contains raw levels, smoothed levels and instantaneous change in levels.
	uniform float audioLevels[4];
	uniform float audioLevelsSmooth[4];
	uniform float audioLevelsChange[4];

	// Pass UVs into fragment shader
	varying vec2 vUV;
	varying vec2 vAudioUV;

	void main() {
	  // Calculate correct UV offset for sampling cyclic audio buffer.
	  vec2 audioUV = vec2(uv.x, uv.y + audioOffset);
	  vUV = uv;

	  // Render time data on a grid.
	  vec3 pos = vec3(
	    position.x,
	    position.z + texture2D(freqData, audioUV).a * 3.0 - .5,
	    -position.y);

	  // Pass correct UV offset to fragment shader.
	  vAudioUV = audioUV;

	  // Project vertex into screen space.
	  gl_Position = projectionMatrix *
	                modelViewMatrix *
	                vec4(pos, 1.0);
	}
</script>

<script type="application/x-glsl" id="fragment">
	vec3 hsv2rgb(vec3 c)
	{
	    vec4 K = vec4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0);
	    vec3 p = abs(fract(c.xxx + K.xyz) * 6.0 - K.www);
	    return c.z * mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), c.y);
	}
	vec3 cie2rgb(vec3 c) {
		mat3 A = mat3(
			2.3706743,-0.9000405,-0.4706338,
			-0.5138850,1.4253036,0.0885814,
			0.0052982,-0.0146949,1.0093968);
		return c * A;
	}
	// Audio data textures
	uniform sampler2D freqData;
	uniform sampler2D timeData;

	// Offset and sample size for sampling data textures
	uniform float audioOffset;
	uniform vec2 audioStep;

	// Beat detection. Is = 0 or 1, Was = smoothed value.
	uniform float audioIsBeat;
	uniform float audioWasBeat;

	// Precalculated audio levels, the components being (all, bass, mid, treble).
	// Contains raw levels, smoothed levels and instantaneous change in levels.
	uniform float audioLevels[4];
	uniform float audioLevelsSmooth[4];
	uniform float audioLevelsChange[4];

	// Pass UVs into fragment shader
	varying vec2 vUV;
	varying vec2 vAudioUV;

	void main() {
	  float alpha = texture2D(freqData, vAudioUV).a;
	  vec3 beat = vec3(0.5) * audioWasBeat;
	  vec3 grad = cie2rgb(vec3( vUV.x, 1. -alpha, vUV.y)) ;
	  gl_FragColor = vec4(grad + beat, 1.0) ;
	}
</script>

<script>

	// console.log(audioSource)


function initScene(scene, camera, controls, renderer) {
    controls.target.set(0, 0, 0);
	controls.noZoom = false;
	controls.noPan = false;

	renderer.setSize( window.innerWidth, window.innerHeight );
	renderer.setClearColor(0x888888);
	renderer.autoClear = false;
	var container = $('body');
    container.append(renderer.domElement);
}

function drawPlane(scene, audioTextures, params) { // res, width, center) {
	var geometry = new ThreeAudio.GridGeometry(audioTextures, params.width, params.width, params.res, 10000 );
	var vertexShader = document.getElementById( 'vertex' ).textContent;
    var fragmentShader = document.getElementById( 'fragment' ).textContent;
    var material = new ThreeAudio.Material(audioTextures, vertexShader, fragmentShader);

	var plane = new THREE.Mesh( geometry, material );
	plane.position.copy(params.center);
	plane.rotation.z = -3.14/2;
	// scene.add( getAxes(1) );
	scene.add( plane );
}

$( document ).ready(function() {
	var scene = new THREE.Scene();
	var camera = new THREE.PerspectiveCamera( 69, window.innerWidth / window.innerHeight, 0.0001, 1000 );
    var controls = new THREE.TrackballControls(camera);
	var renderer = new THREE.WebGLRenderer();

	var audioSource = (new ThreeAudio.Source()).load('/mp3/nth.mp3').play();
	var audioTextures = new ThreeAudio.Textures(renderer, audioSource);	

	initScene(scene, camera, controls, renderer);

	drawPlane(scene, audioTextures, {
		res : 0,
		history : 1024,
		width: 10,
		center : new THREE.Vector3(0, 0, 0)
	});
	var ticks = 0;

	var stats = new Stats();
	stats.domElement.style.position = 'absolute';
	stats.domElement.style.top = '0px';
	$("body").append( stats.domElement );

	camera.position.y = 8;
	camera.position.x = 5;
	camera.up = new THREE.Vector3(1,0,0);

	camera.lookAt(new THREE.Vector3(0,0,0));

	function render() {
		ticks++;
		scene.rotation.x += 0.001;
		scene.updateMatrix();
		controls.update();

		renderer.render( scene, camera );
		requestAnimationFrame( render );
		audioTextures.update()
     	stats.update();

	}
	render();
});
</script>

</body>
</html>