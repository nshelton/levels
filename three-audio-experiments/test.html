<html><head>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.8.2/underscore-min.js"></script>
	<script src="/js/three.min.js"></script>
	<script src="/js/three.util.js"></script>
	<script src="/three-audio-experiments/vendor/microevent.js"></script>
	<script src="/three-audio-experiments/vendor/dsp.js"></script>
	<script src="/js/TrackballControls.js"></script>
	<script src="/js/jquery.min.js"></script>
	<script src="/js/stats.min.js"></script>
	<script src="/three-audio-experiments/build/ThreeAudio.js"></script>



</head>
<body style="margin:0">

<!-- audio material shader -->
<script type="application/x-glsl" id="vertex">
	// Audio data textures
	uniform sampler2D freqData;
	uniform sampler2D timeData;
	// Offset and sample size for sampling data textures
	uniform float audioOffset;
	uniform vec2 audioStep;
	// Beat detection. Is = 0 or 1, Was = smoothed value.
	uniform float audioIsBeat;
	uniform float audioWasBeat;
	// Precalculated audio levels, the components being (all, bass, mid, treble).
	// Contains raw levels, smoothed levels and instantaneous change in levels.
	uniform float audioLevels[4];
	uniform float audioLevelsSmooth[4];
	uniform float audioLevelsChange[4];
	// Pass UVs into fragment shader
	varying vec2 vUV;
	varying vec2 vAudioUV;
	void main() {
	  // Calculate correct UV offset for sampling cyclic audio buffer.
	  vec2 audioUV = vec2(uv.x, uv.y + audioOffset);
	  vUV = uv;
	  // Render time data on a grid.
	  vec3 pos = vec3(
	    position.x,
	    position.z + texture2D(freqData, audioUV).a * 3.0 - .5,
	    -position.y);
	  // Pass correct UV offset to fragment shader.
	  vAudioUV = audioUV;
	  // Project vertex into screen space.
	  gl_Position = projectionMatrix *
	                modelViewMatrix *
	                vec4(pos, 1.0);
	}
</script>

<script type="application/x-glsl" id="fragment">
	vec3 hsv2rgb(vec3 c)
	{
	    vec4 K = vec4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0);
	    vec3 p = abs(fract(c.xxx + K.xyz) * 6.0 - K.www);
	    return c.z * mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), c.y);
	}
	// Audio data textures
	uniform sampler2D freqData;
	uniform sampler2D timeData;
	// Offset and sample size for sampling data textures
	uniform float audioOffset;
	uniform vec2 audioStep;
	// Beat detection. Is = 0 or 1, Was = smoothed value.
	uniform float audioIsBeat;
	uniform float audioWasBeat;
	// Precalculated audio levels, the components being (all, bass, mid, treble).
	// Contains raw levels, smoothed levels and instantaneous change in levels.
	uniform float audioLevels[4];
	uniform float audioLevelsSmooth[4];
	uniform float audioLevelsChange[4];
	// Pass UVs into fragment shader
	varying vec2 vUV;
	varying vec2 vAudioUV;
	void main() {
	  float alpha = texture2D(freqData, vAudioUV).a;
	  vec3 beat = vec3(1.0,0.0,1.0) * audioWasBeat;
	  vec3 freq = hsv2rgb(vec3(1.0-alpha,1.0,1.0)) * alpha;
	  vec4 color = vec4(freq+beat, 1.0);
	  gl_FragColor = color;
	}
</script>

<script>
	// console.log(audioSource)
function initScene(scene, camera, controls, renderer) {
    controls.target.set(0, 0, 0);
    camera.position.set(10, 0, 0)
	controls.noZoom = false;
	controls.noPan = false;
	renderer.setSize( window.innerWidth, window.innerHeight );
	renderer.setClearColor(0x888888);
	renderer.autoClear = false;
	var container = $('body');
    container.append(renderer.domElement);
}
function drawPlane(scene, audioTextures, params) { // res, width, center) {
	var geometry = new ThreeAudio.GridGeometry(audioTextures, params.width, params.width, params.res, 10000 );
	var vertexShader = document.getElementById( 'vertex' ).textContent;
    var fragmentShader = document.getElementById( 'fragment' ).textContent;
    var material = new ThreeAudio.Material(audioTextures, vertexShader, fragmentShader);
	var plane = new THREE.Mesh( geometry, material );
	plane.position.copy(params.center);
	plane.rotation.z = -3.14/2;
	// scene.add( getAxes(1) );
	scene.add( plane );
}
$( document ).ready(function() {
	var scene = new THREE.Scene();
	var camera = new THREE.PerspectiveCamera( 69, window.innerWidth / window.innerHeight, 0.0001, 1000 );
    var controls = new THREE.TrackballControls(camera);
	var renderer = new THREE.WebGLRenderer();
	var audioSource = (new ThreeAudio.Source()).load('/mp3/nth.mp3').play();
	var audioTextures = new ThreeAudio.Textures(renderer, audioSource);	
	initScene(scene, camera, controls, renderer);
	drawPlane(scene, audioTextures, {
		res : 0,
		history : 1024,
		width: 10,
		center : new THREE.Vector3(0, 0, 0)
	});
	var ticks = 0;
	var stats = new Stats();
	stats.domElement.style.position = 'absolute';
	stats.domElement.style.top = '0px';
	$("body").append( stats.domElement );
	function render() {
		ticks++;
		camera.position.y = 8*Math.cos(ticks/1000);
		camera.position.z = 8*Math.sin(ticks/1000);
		camera.position.x = 5
		camera.up = new THREE.Vector3(1,0,0);
		camera.lookAt(new THREE.Vector3(0,0,0));
		// controls.update();
		renderer.render( scene, camera );
		requestAnimationFrame( render );
		audioTextures.update()
     	stats.update();
	}
	render();
});
</script>

</body>
</html>